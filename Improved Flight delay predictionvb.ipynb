{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight delay prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font Font size=\"3\" color='red'>\n",
    "IMPORTANT NOTE: This notebook demonstrates the usefulness of submitting a spark job to a cluster (compared to running interactively against a local spark in the cells below). It is NOT recommended to run this notebook locally!. In order to run this notebook locally you will need to STOP all other notebooks. Moreover, running this notebook locally will take a long time.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use the [Flight Dataset](http://stat-computing.org/dataexpo/2009/the-data.html). We will build a classification model to predict airline delay from historial flight data. This dataset is 5 GB and contains 52 million flight records. Processing of such a large data set requires use of a Spark Cluster. \n",
    "\n",
    "First, we import some python packages that we need for this use-case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Getting the data and creating the RDD\n",
    "As mentioned, we will use the complete dataset, containing nearly 50 million flights. The file is provided as a __.csv file__. Size of this dataset is 5 GB. We read data into a __RDD__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget --quiet  --output-document 2001-2008-merged.csv https://ibm.box.com/shared/static/dibichwe630efqw4rdrj1j4cdt3u7bhu.csv 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textFile = sc.textFile(\"2001-2008-merged.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Caching\n",
    "In this section, we remove the header of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textFileRDD=textFile.map(lambda x: x.split(','))\n",
    "header = textFileRDD.first()\n",
    "textRDD = textFileRDD.filter(lambda r: r != header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataframe from RDD\n",
    "A DataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in Python, but with richer optimizations under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(r):\n",
    "    try:\n",
    "        x=Row(Year=int(r[0]),\\\n",
    "          Month=int(r[1]),\\\n",
    "          DayofMonth=int(r[2]),\\\n",
    "          DayOfWeek=int(r[3]),\\\n",
    "          DepTime=int(float(r[4])), \\\n",
    "          CRSDepTime=int(r[5]),\\\n",
    "          ArrTime=int(float(r[6])),\\\n",
    "          CRSArrTime=int(r[7]), \\\n",
    "          UniqueCarrier=r[8],\\\n",
    "          DepDelay=int(float(r[15])),\\\n",
    "          Origin=r[16],\\\n",
    "          Dest=r[17], \\\n",
    "          Distance=int(float(r[18])))  \n",
    "    except:\n",
    "        x=None  \n",
    "    return x\n",
    "rowRDD=textRDD.map(lambda r: parse(r)).filter(lambda r:r != None)\n",
    "airline_df = sqlContext.createDataFrame(rowRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we add a new column to our data frame to determine the delayed flight against non-delayed ones. Later, we use this column as target/label column in the classification process. So, a binary variable is defined as __DepDelayed__ which its value __True__ for flights having 15 mins or more of delay, and __False__ otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airline_df=airline_df.withColumn('DepDelayed',airline_df['DepDelay']>15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define hour function to obtain hour of day\n",
    "def hour_ex(x): \n",
    "    h=int(str(int(x)).zfill(4)[:2])\n",
    "    return h\n",
    "# register as a UDF \n",
    "f = udf(hour_ex, IntegerType())\n",
    "#CRSDepTime: scheduled departure time (local, hhmm)\n",
    "airline_df=airline_df.withColumn('hour', f(airline_df.CRSDepTime))\n",
    "airline_df.registerTempTable(\"airlineDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Airport selection\n",
    "In the following cell we select the airline that we want to predict its delay. To simplify, we will build a supervised learning model to predict flight delays for flights leaving JFK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Origin_Airport=\"JFK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ORG =sqlContext.sql(\"SELECT * from airlineDF WHERE Origin='\"+ Origin_Airport+\"'\")\n",
    "df_ORG.registerTempTable(\"df_ORG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Feature selection\n",
    "In the next two cell we select the features that we need to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_model=df_ORG\n",
    "stringIndexer1 = StringIndexer(inputCol=\"Origin\", outputCol=\"originIndex\")\n",
    "model_stringIndexer = stringIndexer1.fit(df_model)\n",
    "indexedOrigin = model_stringIndexer.transform(df_model)\n",
    "encoder1 = OneHotEncoder(dropLast=False, inputCol=\"originIndex\", outputCol=\"originVec\")\n",
    "df_model = encoder1.transform(indexedOrigin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use __labeled point__ to make local vectors associated with a label/response. In MLlib, labeled points are used in supervised learning algorithms and they are stored as doubles. For binary classification, a label should be either 0 (negative) or 1 (positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=['Year','Month','DayofMonth','DayOfWeek','hour','Distance','originVec'],\n",
    "    outputCol=\"features\")\n",
    "output = assembler.transform(df_model)\n",
    "airlineRDD=output.map(lambda row: LabeledPoint([0,1][row['DepDelayed']],row['features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Spliting dataset into train and test dtasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainRDD,testRDD=airlineRDD.randomSplit([0.7,0.3])\n",
    "model = LogisticRegressionWithLBFGS.train(trainRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on testing data\n",
    "labelsAndPreds = testRDD.map(lambda p: (p.label, model.predict(p.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conf(r):\n",
    "    if r[0] == r[1] ==1: x= 'TP'\n",
    "    if r[0] == r[1] ==0: x= 'TN'\n",
    "    if r[0] == 1 and  r[1] ==0: x= 'FN'\n",
    "    if r[0] == 0 and  r[1] ==1: x= 'FP'\n",
    "    return (x)\n",
    "acc1=labelsAndPreds.map(lambda (v, p): ((v, p),1)).reduceByKey(lambda a, b: a + b).take(5)\n",
    "acc=[(conf(x[0]),x[1]) for x in acc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP=TN=FP=FN=0.0\n",
    "for x in acc: \n",
    "    if x[0]=='TP': TP= x[1]\n",
    "    if x[0]=='TN': TN= x[1]\n",
    "    if x[0]=='FP': FP= x[1]\n",
    "    if x[0]=='FN': FN= x[1]\n",
    "eps=sys.float_info.epsilon\n",
    "Accuracy= (TP+TN) / (TP + TN+ FP+FN+eps) \n",
    "print \"Model Accuracy for JFK: %1.2f %%\" % (Accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}